{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"datasets/UrbanSound8K/UrbanSound8K.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "engine_idling    1000\n",
       "siren             929\n",
       "car_horn          429\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir los sonidos críticos que queremos detectar\n",
    "critical_sounds = ['car_horn', 'siren', 'engine_idling']\n",
    "\n",
    "# Filtrar el dataset\n",
    "df_filtered = df[df['class'].isin(critical_sounds)]\n",
    "\n",
    "# Mostrar la cantidad de sonidos seleccionados\n",
    "df_filtered['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100648-1-0-0.wav</td>\n",
       "      <td>100648</td>\n",
       "      <td>4.823402</td>\n",
       "      <td>5.471927</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100648-1-1-0.wav</td>\n",
       "      <td>100648</td>\n",
       "      <td>8.998279</td>\n",
       "      <td>10.052132</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100648-1-2-0.wav</td>\n",
       "      <td>100648</td>\n",
       "      <td>16.699509</td>\n",
       "      <td>17.104837</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100648-1-3-0.wav</td>\n",
       "      <td>100648</td>\n",
       "      <td>17.631764</td>\n",
       "      <td>19.253075</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100648-1-4-0.wav</td>\n",
       "      <td>100648</td>\n",
       "      <td>25.332994</td>\n",
       "      <td>27.197502</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     slice_file_name    fsID      start        end  salience  fold  classID  \\\n",
       "9   100648-1-0-0.wav  100648   4.823402   5.471927         2    10        1   \n",
       "10  100648-1-1-0.wav  100648   8.998279  10.052132         2    10        1   \n",
       "11  100648-1-2-0.wav  100648  16.699509  17.104837         2    10        1   \n",
       "12  100648-1-3-0.wav  100648  17.631764  19.253075         2    10        1   \n",
       "13  100648-1-4-0.wav  100648  25.332994  27.197502         2    10        1   \n",
       "\n",
       "       class  \n",
       "9   car_horn  \n",
       "10  car_horn  \n",
       "11  car_horn  \n",
       "12  car_horn  \n",
       "13  car_horn  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraer Características de Audio (MFCCs)\n",
    "Cada archivo de audio se convierte en un conjunto de coeficientes MFCC, que son características esenciales para el reconocimiento de sonidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_name, sr=44100)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        mfccs = np.mean(mfccs.T, axis=0)\n",
    "        return mfccs\n",
    "    except Exception as e:\n",
    "        print(\"❌ Error en archivo:\", file_name, str(e))\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características extraídas. Tamaño del dataset: (2358, 40)\n"
     ]
    }
   ],
   "source": [
    "X, y = [], []\n",
    "\n",
    "for index, row in df_filtered.iterrows():\n",
    "    file_name = os.path.join(\n",
    "        \"datasets\", \"UrbanSound8K\", f\"fold{row['fold']}\", row[\"slice_file_name\"]\n",
    "    ) \n",
    "\n",
    "    features = extract_features(file_name)\n",
    "\n",
    "    if features is not None:\n",
    "        X.append(features)\n",
    "        y.append(row[\"class\"])\n",
    "\n",
    "# Convertir a arrays de NumPy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Características extraídas. Tamaño del dataset:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases codificadas: ['car_horn' 'engine_idling' 'siren']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"Clases codificadas:\", label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos divididos en entrenamiento y prueba:\n",
      "   - Entrenamiento: 1886 muestras\n",
      "   - Prueba: 472 muestras\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Datos divididos en entrenamiento y prueba:\")\n",
    "print(\"   - Entrenamiento:\", X_train.shape[0], \"muestras\")\n",
    "print(\"   - Prueba:\", X_test.shape[0], \"muestras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de IA construido.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yordy\\Documents\\dev\\bootcamp\\inteligencia_artificial\\fundacion_esplai\\safe_drive\\safe_drive_models\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(40,)),  # Capa oculta 1\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),  # Capa oculta 2\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),  # Capa oculta 3\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')  # Capa de salida\n",
    "])\n",
    "\n",
    "print(\"Modelo de IA construido.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo compilado.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"Modelo compilado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento...\n",
      "Epoch 1/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4546 - loss: 9.5446 - val_accuracy: 0.7648 - val_loss: 0.6805\n",
      "Epoch 2/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5718 - loss: 2.0033 - val_accuracy: 0.7839 - val_loss: 0.6154\n",
      "Epoch 3/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6490 - loss: 1.1382 - val_accuracy: 0.8178 - val_loss: 0.4974\n",
      "Epoch 4/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6826 - loss: 1.0009 - val_accuracy: 0.8517 - val_loss: 0.4683\n",
      "Epoch 5/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7130 - loss: 0.7592 - val_accuracy: 0.8686 - val_loss: 0.4119\n",
      "Epoch 6/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7761 - loss: 0.5865 - val_accuracy: 0.8814 - val_loss: 0.3773\n",
      "Epoch 7/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7988 - loss: 0.5318 - val_accuracy: 0.8919 - val_loss: 0.3352\n",
      "Epoch 8/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8141 - loss: 0.5494 - val_accuracy: 0.8877 - val_loss: 0.3174\n",
      "Epoch 9/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.5014 - val_accuracy: 0.9153 - val_loss: 0.2934\n",
      "Epoch 10/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8318 - loss: 0.4570 - val_accuracy: 0.9047 - val_loss: 0.2753\n",
      "Epoch 11/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.3802 - val_accuracy: 0.8814 - val_loss: 0.3005\n",
      "Epoch 12/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8504 - loss: 0.3853 - val_accuracy: 0.9110 - val_loss: 0.2760\n",
      "Epoch 13/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8642 - loss: 0.3280 - val_accuracy: 0.9131 - val_loss: 0.2630\n",
      "Epoch 14/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8854 - loss: 0.3000 - val_accuracy: 0.9237 - val_loss: 0.2429\n",
      "Epoch 15/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 0.2595 - val_accuracy: 0.9237 - val_loss: 0.2294\n",
      "Epoch 16/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8979 - loss: 0.2779 - val_accuracy: 0.9258 - val_loss: 0.2177\n",
      "Epoch 17/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.2580 - val_accuracy: 0.9301 - val_loss: 0.2326\n",
      "Epoch 18/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2494 - val_accuracy: 0.9343 - val_loss: 0.2012\n",
      "Epoch 19/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9343 - loss: 0.1821 - val_accuracy: 0.9322 - val_loss: 0.2074\n",
      "Epoch 20/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.2040 - val_accuracy: 0.9407 - val_loss: 0.2080\n",
      "Epoch 21/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.1880 - val_accuracy: 0.9428 - val_loss: 0.2043\n",
      "Epoch 22/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.1960 - val_accuracy: 0.9492 - val_loss: 0.1862\n",
      "Epoch 23/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9435 - loss: 0.1662 - val_accuracy: 0.9449 - val_loss: 0.1907\n",
      "Epoch 24/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9368 - loss: 0.1677 - val_accuracy: 0.9449 - val_loss: 0.1923\n",
      "Epoch 25/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9538 - loss: 0.1393 - val_accuracy: 0.9555 - val_loss: 0.1749\n",
      "Epoch 26/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.1411 - val_accuracy: 0.9407 - val_loss: 0.1757\n",
      "Epoch 27/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.1418 - val_accuracy: 0.9513 - val_loss: 0.1691\n",
      "Epoch 28/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9613 - loss: 0.1126 - val_accuracy: 0.9534 - val_loss: 0.1625\n",
      "Epoch 29/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9550 - loss: 0.1155 - val_accuracy: 0.9492 - val_loss: 0.1686\n",
      "Epoch 30/30\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9627 - loss: 0.1296 - val_accuracy: 0.9513 - val_loss: 0.1755\n",
      "Entrenamiento finalizado.\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando entrenamiento...\")\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
    "print(\"Entrenamiento finalizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'urban_sound_model.h5'.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"datasets/UrbanSound8K/data/urban_sound_model.h5\")\n",
    "\n",
    "print(\"Modelo guardado como 'urban_sound_model.h5'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yordy\\AppData\\Local\\Temp\\tmpv_9psspo\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\yordy\\AppData\\Local\\Temp\\tmpv_9psspo\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\yordy\\AppData\\Local\\Temp\\tmpv_9psspo'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 40), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2536270200272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2536270199888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2536272988112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2536272987920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2536272991376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2536272992336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2536272993296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2536272993872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Modelo convertido y guardado como sound_detector.tflite\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('datasets/UrbanSound8K/data/urban_sound_model.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('datasets/UrbanSound8K/data/urban_sound_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Modelo convertido y guardado como sound_detector.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9585 - loss: 0.1418 \n",
      "Precisión del modelo en datos de prueba: 0.95\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Precisión del modelo en datos de prueba: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sound(file_name):\n",
    "    features = extract_features(file_name)\n",
    "    if features is not None:\n",
    "        features = np.array(features).reshape(1, -1)\n",
    "        prediction = model.predict(features)\n",
    "        class_pred = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "        print(f\"🔊 Predicción: {class_pred[0]}\")\n",
    "    else:\n",
    "        print(\"❌ Error al procesar el archivo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>102853-8-0-0.wav</td>\n",
       "      <td>102853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>102853-8-0-1.wav</td>\n",
       "      <td>102853</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>102853-8-0-2.wav</td>\n",
       "      <td>102853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>102853-8-0-3.wav</td>\n",
       "      <td>102853</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>102853-8-0-4.wav</td>\n",
       "      <td>102853</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>96657-8-0-1.wav</td>\n",
       "      <td>96657</td>\n",
       "      <td>122.837051</td>\n",
       "      <td>126.837051</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>96657-8-0-2.wav</td>\n",
       "      <td>96657</td>\n",
       "      <td>123.337051</td>\n",
       "      <td>127.337051</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8576</th>\n",
       "      <td>96657-8-0-3.wav</td>\n",
       "      <td>96657</td>\n",
       "      <td>123.837051</td>\n",
       "      <td>127.837051</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8642</th>\n",
       "      <td>98525-8-0-0.wav</td>\n",
       "      <td>98525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8643</th>\n",
       "      <td>98536-8-0-0.wav</td>\n",
       "      <td>98536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>929 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       slice_file_name    fsID       start         end  salience  fold  \\\n",
       "114   102853-8-0-0.wav  102853    0.000000    4.000000         2     7   \n",
       "115   102853-8-0-1.wav  102853    0.500000    4.500000         2     7   \n",
       "116   102853-8-0-2.wav  102853    1.000000    5.000000         2     7   \n",
       "117   102853-8-0-3.wav  102853    1.500000    5.500000         2     7   \n",
       "118   102853-8-0-4.wav  102853    2.000000    6.000000         2     7   \n",
       "...                ...     ...         ...         ...       ...   ...   \n",
       "8574   96657-8-0-1.wav   96657  122.837051  126.837051         2     8   \n",
       "8575   96657-8-0-2.wav   96657  123.337051  127.337051         2     8   \n",
       "8576   96657-8-0-3.wav   96657  123.837051  127.837051         2     8   \n",
       "8642   98525-8-0-0.wav   98525    0.000000    4.000000         1     7   \n",
       "8643   98536-8-0-0.wav   98536    0.000000    1.358367         1     8   \n",
       "\n",
       "      classID  class  \n",
       "114         8  siren  \n",
       "115         8  siren  \n",
       "116         8  siren  \n",
       "117         8  siren  \n",
       "118         8  siren  \n",
       "...       ...    ...  \n",
       "8574        8  siren  \n",
       "8575        8  siren  \n",
       "8576        8  siren  \n",
       "8642        8  siren  \n",
       "8643        8  siren  \n",
       "\n",
       "[929 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# critical_sounds = [\"car_horn\", \"siren\", \"engine_idling\"]\n",
    "df_filtered[df_filtered[\"class\"] == \"siren\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "🔊 Predicción: car_horn\n"
     ]
    }
   ],
   "source": [
    "predict_sound(\"datasets/UrbanSound8K/fold7/99812-1-4-0.wav\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
