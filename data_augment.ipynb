{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "\n",
    "# Cargar un sonido cr铆tico (por ejemplo, sirena)\n",
    "input_path = \"datasets/UrbanSound8K/fold7/102853-8-0-0.wav\"\n",
    "samples, sample_rate = librosa.load(input_path, sr=None)\n",
    "\n",
    "# Crear pipeline de aumentaciones\n",
    "augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "    Shift(min_shift=-0.5, max_shift=0.5, p=0.5)\n",
    "\n",
    "])\n",
    "\n",
    "# Aplicar aumentaciones\n",
    "augmented_samples = augment(samples=samples, sample_rate=sample_rate)\n",
    "\n",
    "# Guardar el nuevo archivo\n",
    "sf.write(\"sirena_aumentada.wav\", augmented_samples, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, TimeStretch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Preparar YAMNet y Augmentaciones\n",
    "# -----------------------------\n",
    "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "\n",
    "augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.01, p=0.5),\n",
    "    PitchShift(min_semitones=-2, max_semitones=2, p=0.5),\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.2, p=0.5)\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Funci贸n para extraer embeddings\n",
    "# -----------------------------\n",
    "def extract_embedding(audio, sr=16000):\n",
    "    waveform = tf.convert_to_tensor(audio, dtype=tf.float32)\n",
    "    scores, embeddings, spectrogram = yamnet_model(waveform)\n",
    "    return tf.reduce_mean(embeddings, axis=0).numpy()\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Cargar y procesar tus audios\n",
    "# -----------------------------\n",
    "def load_dataset(data_dir):\n",
    "    X, y = [], []\n",
    "    for label in os.listdir(data_dir):\n",
    "        class_dir = os.path.join(data_dir, label)\n",
    "        for file in os.listdir(class_dir):\n",
    "            file_path = os.path.join(class_dir, file)\n",
    "            audio, sr = librosa.load(file_path, sr=16000)\n",
    "            \n",
    "            # Aumentaci贸n\n",
    "            augmented = augment(samples=audio, sample_rate=sr)\n",
    "            \n",
    "            # Extraer embeddings original y aumentado\n",
    "            emb_original = extract_embedding(audio)\n",
    "            emb_augmented = extract_embedding(augmented)\n",
    "            \n",
    "            X.append(emb_original)\n",
    "            X.append(emb_augmented)\n",
    "            y.append(label)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Entrenar un clasificador\n",
    "# -----------------------------\n",
    "def train_classifier(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=500, random_state=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"\\n Evaluaci贸n del modelo:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n Matriz de confusi贸n:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return clf\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Ejecutar todo\n",
    "# -----------------------------\n",
    "# Estructura esperada:\n",
    "# dataset/\n",
    "#    sirena/\n",
    "#    bocina/\n",
    "#    alarma/\n",
    "\n",
    "DATASET_DIR = \"dataset\"  # Ruta a tus audios organizados por clase\n",
    "\n",
    "X, y = load_dataset(DATASET_DIR)\n",
    "model = train_classifier(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yordy\\Documents\\dev\\bootcamp\\inteligencia_artificial\\fundacion_esplai\\safe_drive\\safe_drive_models\\env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yordy\\Documents\\dev\\bootcamp\\inteligencia_artificial\\fundacion_esplai\\safe_drive\\safe_drive_models\\env\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yordy\\Documents\\dev\\bootcamp\\inteligencia_artificial\\fundacion_esplai\\safe_drive\\safe_drive_models\\env\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yordy\\Documents\\dev\\bootcamp\\inteligencia_artificial\\fundacion_esplai\\safe_drive\\safe_drive_models\\env\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\yordy\\Documents\\dev\\bootcamp\\inteligencia_artificial\\fundacion_esplai\\safe_drive\\safe_drive_models\\env\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model.\n",
    "model = hub.load('https://tfhub.dev/google/yamnet/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the name of the class with the top score when mean-aggregated across frames.\n",
    "def class_names_from_csv(class_map_csv_text):\n",
    "  \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
    "  class_names = []\n",
    "  with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "      class_names.append(row['display_name'])\n",
    "\n",
    "  return class_names\n",
    "\n",
    "class_map_path = model.class_map_path().numpy()\n",
    "class_names = class_names_from_csv(class_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_sample_rate(original_sample_rate, waveform,\n",
    "                       desired_sample_rate=16000):\n",
    "  \"\"\"Resample waveform if required.\"\"\"\n",
    "  if original_sample_rate != desired_sample_rate:\n",
    "    desired_length = int(round(float(len(waveform)) /\n",
    "                               original_sample_rate * desired_sample_rate))\n",
    "    waveform = scipy.signal.resample(waveform, desired_length)\n",
    "  return desired_sample_rate, waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 16000 Hz\n",
      "Total duration: 9.66s\n",
      "Size of the input: 154614\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "ushort format requires 0 <= number <= 65535",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSize of the input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(wav_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Reproducir el audio en Jupyter\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yordy\\Documents\\dev\\bootcamp\\inteligencia_artificial\\fundacion_esplai\\safe_drive\\safe_drive_models\\env\\Lib\\site-packages\\IPython\\lib\\display.py:130\u001b[39m, in \u001b[36mAudio.__init__\u001b[39m\u001b[34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mrate must be specified when data is a numpy array or list of audio samples.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28mself\u001b[39m.data = \u001b[43mAudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_make_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yordy\\Documents\\dev\\bootcamp\\inteligencia_artificial\\fundacion_esplai\\safe_drive\\safe_drive_models\\env\\Lib\\site-packages\\IPython\\lib\\display.py:162\u001b[39m, in \u001b[36mAudio._make_wav\u001b[39m\u001b[34m(data, rate, normalize)\u001b[39m\n\u001b[32m    160\u001b[39m waveobj.setsampwidth(\u001b[32m2\u001b[39m)\n\u001b[32m    161\u001b[39m waveobj.setcomptype(\u001b[33m'\u001b[39m\u001b[33mNONE\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mNONE\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m \u001b[43mwaveobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwriteframes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m val = fp.getvalue()\n\u001b[32m    164\u001b[39m waveobj.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\wave.py:558\u001b[39m, in \u001b[36mWave_write.writeframes\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwriteframes\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwriteframesraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._datalength != \u001b[38;5;28mself\u001b[39m._datawritten:\n\u001b[32m    560\u001b[39m         \u001b[38;5;28mself\u001b[39m._patchheader()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\wave.py:547\u001b[39m, in \u001b[36mWave_write.writeframesraw\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[32m    546\u001b[39m     data = \u001b[38;5;28mmemoryview\u001b[39m(data).cast(\u001b[33m'\u001b[39m\u001b[33mB\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ensure_header_written\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    548\u001b[39m nframes = \u001b[38;5;28mlen\u001b[39m(data) // (\u001b[38;5;28mself\u001b[39m._sampwidth * \u001b[38;5;28mself\u001b[39m._nchannels)\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._convert:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\wave.py:588\u001b[39m, in \u001b[36mWave_write._ensure_header_written\u001b[39m\u001b[34m(self, datasize)\u001b[39m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._framerate:\n\u001b[32m    587\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[33m'\u001b[39m\u001b[33msampling rate not specified\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_write_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\wave.py:600\u001b[39m, in \u001b[36mWave_write._write_header\u001b[39m\u001b[34m(self, initlength)\u001b[39m\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mOSError\u001b[39;00m):\n\u001b[32m    599\u001b[39m     \u001b[38;5;28mself\u001b[39m._form_length_pos = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m \u001b[38;5;28mself\u001b[39m._file.write(\u001b[43mstruct\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpack\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m<L4s4sLHHLLHH4s\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m36\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_datalength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mWAVE\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfmt \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43mWAVE_FORMAT_PCM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_nchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_framerate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_nchannels\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_framerate\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sampwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_nchannels\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sampwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sampwidth\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._form_length_pos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    607\u001b[39m     \u001b[38;5;28mself\u001b[39m._data_length_pos = \u001b[38;5;28mself\u001b[39m._file.tell()\n",
      "\u001b[31merror\u001b[39m: ushort format requires 0 <= number <= 65535"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Ruta al archivo de audio\n",
    "wav_file_name = 'datasets/UrbanSound8K/fold7/99812-1-4-0.wav'\n",
    "\n",
    "# Leer el archivo WAV\n",
    "sample_rate, wav_data = wavfile.read(wav_file_name)\n",
    "\n",
    "# Asegurarse de que est茅 a 16000 Hz (YAMNet lo necesita as铆)\n",
    "def ensure_sample_rate(sr, data, target_sr=16000):\n",
    "    if sr != target_sr:\n",
    "        import librosa\n",
    "        data = librosa.resample(data.astype(float), orig_sr=sr, target_sr=target_sr)\n",
    "        return target_sr, data\n",
    "    return sr, data\n",
    "\n",
    "sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)\n",
    "\n",
    "# Mostrar informaci贸n del audio\n",
    "duration = len(wav_data) / sample_rate\n",
    "print(f'Sample rate: {sample_rate} Hz')\n",
    "print(f'Total duration: {duration:.2f}s')\n",
    "print(f'Size of the input: {len(wav_data)}')\n",
    "\n",
    "# Reproducir el audio en Jupyter\n",
    "Audio(wav_data, rate=sample_rate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
